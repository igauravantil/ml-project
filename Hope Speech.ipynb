{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T5gl5cMjk9Xp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "NSutkE-JpNLl"
   },
   "outputs": [],
   "source": [
    "dftamil=pd.read_csv('tamil_train.csv')\n",
    "dfmal=pd.read_csv('malayalam_train.csv')\n",
    "dfeng=pd.read_csv('english_train.csv')\n",
    "dftamiltest=pd.read_csv('tamil_test.csv')\n",
    "dfmaltest=pd.read_csv('malayalam_test.csv')\n",
    "dfengtest=pd.read_csv('english_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16159, 2)\n",
      "(22761, 2)\n",
      "(8563, 2)\n",
      "(2019, 1)\n",
      "(2845, 1)\n",
      "(1070, 12)\n"
     ]
    }
   ],
   "source": [
    "print(dftamil.shape)\n",
    "print(dfeng.shape)\n",
    "print(dfmal.shape)\n",
    "print(dftamiltest.shape)\n",
    "print(dfengtest.shape)\n",
    "print(dfmaltest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmaltest=dfmaltest.drop(['Unnamed: 1','Unnamed: 2','Unnamed: 3','Unnamed: 4','Unnamed: 5','Unnamed: 6','Unnamed: 7','Unnamed: 8','Unnamed: 9','Unnamed: 10','Unnamed: 11'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Konjam methuva pesuninganna nalarukum bro...'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftamiltest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft=pd.DataFrame({\"Realme india product\":[\"Realme india product\"],\n",
    "                 \"not-Tamil\":[\"not-Tamil\"]})\n",
    "dfm=pd.DataFrame({\"@arya s nair may be athile karthikayude charctr bisexual ayirikkum\":[\"@arya s nair may be athile karthikayude charctr bisexual ayirikkum\"],\n",
    "                 \"Non_hope_speech\":[\"Non_hope_speech\"]})\n",
    "dfe=pd.DataFrame({\"these tiktoks radiate gay chaotic energy and i love it\":[\"these tiktoks radiate gay chaotic energy and i love it\"],\n",
    "                 \"Non_hope_speech\":[\"Non_hope_speech\"]})\n",
    "dfttest=pd.DataFrame({\"Konjam methuva pesuninganna nalarukum bro...\":[\"Konjam methuva pesuninganna nalarukum bro...\"]})\n",
    "dfmtest=pd.DataFrame({\"അതെ അണപൊട്ടി ഒഴുകുകയാണ്\":[\"അതെ അണപൊട്ടി ഒഴുകുകയാണ്\"]})\n",
    "dfetest=pd.DataFrame({\"What do you mean by the word sniped?\":[\"What do you mean by the word sniped?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['What do you mean by the word sniped?'], dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "datat=dft.append(dftamil, ignore_index = True)\n",
    "datam=dfm.append(dfmal, ignore_index = True)\n",
    "datae=dfe.append(dfeng, ignore_index = True)\n",
    "datatt=dfttest.append(dftamiltest, ignore_index = True)\n",
    "datamt=dfmtest.append(dfmaltest, ignore_index = True)\n",
    "dataet=dfetest.append(dfengtest, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tamil=datat.rename(columns={\"Realme india product\": \"text\", \"not-Tamil\": \"label\"})\n",
    "data_mal=datam.rename(columns={\"@arya s nair may be athile karthikayude charctr bisexual ayirikkum\": \"text\", \"Non_hope_speech\": \"label\"})\n",
    "data_eng=datae.rename(columns={\"these tiktoks radiate gay chaotic energy and i love it\": \"text\", \"Non_hope_speech\": \"label\"})\n",
    "data_tamiltest=datatt.rename(columns={\"Konjam methuva pesuninganna nalarukum bro...\": \"text\"})\n",
    "data_maltest=datamt.rename(columns={\"അതെ അണപൊട്ടി ഒഴുകുകയാണ്\": \"text\"})\n",
    "data_engtest=dataet.rename(columns={\"What do you mean by the word sniped?\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafinal=pd.concat([data_tamil,data_mal,data_eng])\n",
    "datafinaltest=pd.concat([data_tamiltest,data_maltest,data_engtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47486,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafinal['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = datafinal.sample(frac=1).reset_index(drop=True) #shuffling\n",
    "df_test = datafinaltest.sample(frac=1).reset_index(drop=True) #shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXqhhyESdXzP"
   },
   "source": [
    "# **Cleaning** **dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "kqS4I4SsWFfs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47486,), 'Non_hope_speech')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text=df_train['text'].values\n",
    "final_label=df_train['label'].values\n",
    "final_text.shape,final_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2P3GkhQ2tSwM",
    "outputId": "9055ed7d-1b73-4e18-f593-4b37e12f9a7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\DEVANSH\n",
      "[nltk_data]     JAIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0,47486):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', final_text[i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  ps = PorterStemmer()\n",
    "  all_stopwords = stopwords.words('english')\n",
    "  all_stopwords.remove('not')\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)\n",
    "  corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "sAcXvTCbOAFd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47486, 3000)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 3000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "df_train['Label']=labelencoder.fit_transform(df_train['label'])\n",
    "y = df_train['Label'].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "6CZ-uuI8Oz3Z"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47486, 3000), (47486,))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJ5D543VOIy-",
    "outputId": "5f5e232f-c147-4c0a-a796-4d5244fce1d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.naive_bayes import BernoulliNB\n",
    " clf = BernoulliNB()\n",
    " clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_texttest=df_train['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\DEVANSH\n",
      "[nltk_data]     JAIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpustest = []\n",
    "for i in range(0,47486):\n",
    "  review = re.sub('[^a-zA-Z]', ' ', final_texttest[i])\n",
    "  review = review.lower()\n",
    "  review = review.split()\n",
    "  ps = PorterStemmer()\n",
    "  all_stopwords = stopwords.words('english')\n",
    "  all_stopwords.remove('not')\n",
    "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "  review = ' '.join(review)\n",
    "  corpustest.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 3000)\n",
    "X_test = cv.fit_transform(corpustest).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "5BZQqKbsOXlK"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1UMeJFbYORCR",
    "outputId": "bd5fced8-585b-4ea7-b04e-c0da521cc9c3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-d52b44f438ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Welcome To Colaboratory",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
